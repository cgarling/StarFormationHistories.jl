<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>High-Level Methods for Unconstrained Fitting · StarFormationHistories.jl</title><meta name="title" content="High-Level Methods for Unconstrained Fitting · StarFormationHistories.jl"/><meta property="og:title" content="High-Level Methods for Unconstrained Fitting · StarFormationHistories.jl"/><meta property="twitter:title" content="High-Level Methods for Unconstrained Fitting · StarFormationHistories.jl"/><meta name="description" content="Documentation for StarFormationHistories.jl."/><meta property="og:description" content="Documentation for StarFormationHistories.jl."/><meta property="twitter:description" content="Documentation for StarFormationHistories.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">StarFormationHistories.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Overview</a></li><li><span class="tocitem">Deriving Star Formation Histories from Hess Diagrams</span><ul><li><a class="tocitem" href="../fitting_intro/">Background and Template Construction</a></li><li class="is-active"><a class="tocitem" href>High-Level Methods for Unconstrained Fitting</a><ul class="internal"><li><a class="tocitem" href="#Maximum-Likelihood-Optimization"><span>Maximum Likelihood Optimization</span></a></li><li><a class="tocitem" href="#Posterior-Sampling:-MCMC"><span>Posterior Sampling: MCMC</span></a></li><li><a class="tocitem" href="#Posterior-Sampling:-Change-of-Variables-and-HMC"><span>Posterior Sampling: Change of Variables and HMC</span></a></li><li><a class="tocitem" href="#Maximum-a-Posteriori-Optimization"><span>Maximum a Posteriori Optimization</span></a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Constrained Metallicity Evolution</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../hierarchical/overview/">Overview</a></li><li><input class="collapse-toggle" id="menuitem-2-3-2" type="checkbox"/><label class="tocitem" for="menuitem-2-3-2"><span class="docs-label">AMRs</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../hierarchical/linear_amr/">Linear Age-Metallicity Relation</a></li><li><a class="tocitem" href="../hierarchical/log_amr/">Logarithmic Age-Metallicity Relation</a></li><li><a class="tocitem" href="../hierarchical/fixed_amr/">Fixed Age-Metallicity Relations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3-3"><span class="docs-label">MZRs</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../hierarchical/MZR/MZR/">Mass-Metallicity Relations (MZRs)</a></li></ul></li><li><a class="tocitem" href="../hierarchical/dispersion_models/">Metallicity Dispersion Models</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">Internals</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../internals/">Low-Level Functions</a></li><li><a class="tocitem" href="../kernels/">Kernels</a></li></ul></li></ul></li><li><a class="tocitem" href="../../examples/">Examples</a></li><li><a class="tocitem" href="../../simulate/">Simulating Color-Magnitude Diagrams</a></li><li><a class="tocitem" href="../../binaries/">Binary Systems</a></li><li><a class="tocitem" href="../../helpers/">Helper Functions</a></li><li><a class="tocitem" href="../../doc_index/">Index</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Deriving Star Formation Histories from Hess Diagrams</a></li><li class="is-active"><a href>High-Level Methods for Unconstrained Fitting</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>High-Level Methods for Unconstrained Fitting</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/cgarling/StarFormationHistories.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/cgarling/StarFormationHistories.jl/blob/main/docs/src/fitting/unconstrained.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="High-Level-Methods-for-Unconstrained-Fitting"><a class="docs-heading-anchor" href="#High-Level-Methods-for-Unconstrained-Fitting">High-Level Methods for Unconstrained Fitting</a><a id="High-Level-Methods-for-Unconstrained-Fitting-1"></a><a class="docs-heading-anchor-permalink" href="#High-Level-Methods-for-Unconstrained-Fitting" title="Permalink"></a></h1><h2 id="Maximum-Likelihood-Optimization"><a class="docs-heading-anchor" href="#Maximum-Likelihood-Optimization">Maximum Likelihood Optimization</a><a id="Maximum-Likelihood-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Maximum-Likelihood-Optimization" title="Permalink"></a></h2><p>Template construction is by far the most complicated step in the fitting procedure. Once your templates have been constructed, fitting them to an observed Hess diagram amounts to maximization of the Poisson likelihood ratio (Dolphin 2002). It is possible to construct more complicated hierarchical models including things like metallicity distribution functions; we discuss these in the next section. In this section we discuss methods for fitting where the only constraint is that star formation rates cannot be negative. We provide the <a href="#StarFormationHistories.construct_x0"><code>StarFormationHistories.construct_x0</code></a> method to help with setting the initial guess for this optimization. </p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StarFormationHistories.construct_x0" href="#StarFormationHistories.construct_x0"><code>StarFormationHistories.construct_x0</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">x0::typeof(logage) = construct_x0(logAge::AbstractVector{T},
                                  T_max::Number;
                                  normalize_value::Number=one(T)) where T &lt;: Number</code></pre><p>Generates a vector of initial stellar mass normalizations for input to <a href="#StarFormationHistories.fit_templates"><code>fit_templates</code></a> or <a href="#StarFormationHistories.hmc_sample"><code>hmc_sample</code></a> with a total stellar mass of <code>normalize_value</code> such that the implied star formation rate is constant across the provided <code>logAge</code> vector that contains the <code>log10(Age [yr])</code> of each isochrone that you are going to input as models. For the purposes of computing the constant star formation rate, the provided <code>logAge</code> are treated as left-bin edges, with the final right-bin edge being <code>T_max</code>, which has units of Gyr. For example, you might have <code>logAge=[6.6, 6.7, 6.8]</code> in which case a final logAge of 6.9 would give equal bin widths. In this case you would set <code>T_max = exp10(6.9) / 1e9 ≈ 0.0079</code> so that the width of the final bin for the star formation rate calculation has the same <code>log10(Age [yr])</code> step as the other bins.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; x0 = construct_x0(repeat([7.0,8.0,9.0],3), 10.0; normalize_value=5.0)
9-element Vector{Float64}: ...

julia&gt; sum(x0)
4.99... # Close to `normalize_value`.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cgarling/StarFormationHistories.jl/blob/901f1c0f1a50ab9b90658688127cd8c6ecefd2e6/src/fitting/utilities.jl#L15-L30">source</a></section></article><p>When it comes to performing the optimization, the simplest method we offer is <a href="#StarFormationHistories.fit_templates_lbfgsb"><code>StarFormationHistories.fit_templates_lbfgsb</code></a>. This will optimize one coefficient per template; there is no overarching metallicity evolution or other constraint, besides that the stellar masses of the populations cannot be negative. This performs a maximum likelihood optimization with the bounded quasi-Newton LBFGS method as implemented in <a href="http://users.iems.northwestern.edu/~nocedal/lbfgsb.html">L-BFGS-B</a> and wrapped in <a href="https://github.com/Gnimuc/LBFGSB.jl">LBFGS.jl</a> with analytic gradients. It is fast and converges fairly reliably, even when the initial guess is not particularly close to the maximum likelihood estimate. It provides no uncertainty estimation. It is normal for some of the coefficients to converge to zero.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StarFormationHistories.fit_templates_lbfgsb" href="#StarFormationHistories.fit_templates_lbfgsb"><code>StarFormationHistories.fit_templates_lbfgsb</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">(-logL, coeffs) = 
fit_templates_lbfgsb(models::AbstractVector{T},
                     data::AbstractMatrix{&lt;:Number};
                     x0::AbstractVector{&lt;:Number} = ones(S,length(models)),
                     factr::Number=1e-12,
                     pgtol::Number=1e-5,
                     iprint::Integer=0,
                     kws...) where {S &lt;: Number, T &lt;: AbstractMatrix{S}}</code></pre><p>Finds the coefficients <code>coeffs</code> that maximize the Poisson likelihood ratio (equations 7–10 in <a href="https://ui.adsabs.harvard.edu/abs/2002MNRAS.332...91D">Dolphin 2002</a>) for the composite Hess diagram model <code>sum(models .* coeffs)</code> given the provided templates <code>models</code> and the observed Hess diagram <code>data</code> using the box-constrained LBFGS method provided by <a href="https://github.com/Gnimuc/LBFGSB.jl">LBFGSB.jl</a>. </p><p><strong>Arguments</strong></p><ul><li><code>models::AbstractVector{AbstractMatrix{&lt;:Number}}</code>: the list of template Hess diagrams for the simple stellar populations (SSPs) being considered; all must have the same size.</li><li><code>data::AbstractMatrix{&lt;:Number}</code>: the observed Hess diagram; must match the size of the templates contained in <code>models</code>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>x0</code>: The vector of initial guesses for the stellar mass coefficients. You should basically always be calculating and passing this keyword argument; we provide <a href="#StarFormationHistories.construct_x0"><code>StarFormationHistories.construct_x0</code></a> to prepare <code>x0</code> assuming constant star formation rate, which is typically a good initial guess.</li><li><code>factr::Number</code>: Keyword argument passed to <code>LBFGSB.lbfgsb</code>; essentially a relative tolerance for convergence based on the inter-iteration change in the objective function.</li><li><code>pgtol::Number</code>: Keyword argument passed to <code>LBFGSB.lbfgsb</code>; essentially a relative tolerance for convergence based on the inter-iteration change in the projected gradient of the objective.</li><li><code>iprint::Integer</code>: Keyword argument passed to <code>LBFGSB.lbfgsb</code> controlling how much information is printed to the terminal. Setting to <code>1</code> can sometimes be helpful to diagnose convergence issues. Setting to <code>-1</code> will disable printing.</li></ul><p>Other <code>kws...</code> are passed to <code>LBFGSB.lbfgsb</code>.</p><p><strong>Returns</strong></p><ul><li><code>-logL::Number</code>: the minimum negative log-likelihood found by the optimizer.</li><li><code>coeffs::Vector{&lt;:Number}</code>: the maximum likelihood estimate for the coefficient vector. </li></ul><p><strong>Notes</strong></p><ul><li>It can be helpful to normalize your <code>models</code> to contain realistic total stellar masses to aid convergence stability; for example, if the total stellar mass of your population is 10^7 solar masses, then you might normalize your templates to contain 10^3 solar masses. If you are using <a href="../fitting_intro/#StarFormationHistories.partial_cmd_smooth"><code>partial_cmd_smooth</code></a> to construct the templates, you can specify this normalization via the <code>normalize_value</code> keyword. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cgarling/StarFormationHistories.jl/blob/901f1c0f1a50ab9b90658688127cd8c6ecefd2e6/src/fitting/solvers.jl#L40-L69">source</a></section><section><div><pre><code class="language-julia hljs">fit_templates_lbfgsb(models::AbstractMatrix{S},
                     data::AbstractVector{&lt;:Number};
                     x0::AbstractVector{&lt;:Number} = ones(S,size(models,2)),
                     factr::Number=1e-12,
                     pgtol::Number=1e-5,
                     iprint::Integer=0,
                     kws...) where S &lt;: Number</code></pre><p>This call signature supports the flattened formats for <code>models</code> and <code>data</code>. See the notes for the flattened call signature of <a href="../internals/#StarFormationHistories.composite!"><code>StarFormationHistories.composite!</code></a> for more details.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cgarling/StarFormationHistories.jl/blob/901f1c0f1a50ab9b90658688127cd8c6ecefd2e6/src/fitting/solvers.jl#L71-L82">source</a></section></article><p>This method simply minimizes the negative logarithm of the Poisson likelihood ratio (Equation 10 in Dolphin 2002),</p><p class="math-container">\[- \text{ln} \, \mathscr{L} = \sum_i m_i - n_i \times \left( 1 - \text{ln} \, \left( \frac{n_i}{m_i} \right) \right)\]</p><p>where <span>$m_i$</span> is bin <span>$i$</span> of the complex model and <span>$n_i$</span> is bin <span>$i$</span> of the observed Hess diagram; this can therefore be thought of as computing the maximum likelihood estimate.</p><p>We also provide <a href="#StarFormationHistories.fit_templates_fast"><code>StarFormationHistories.fit_templates_fast</code></a>, which is the fastest method we offer for deriving a maximum likelihood estimate for the type of model described above.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StarFormationHistories.fit_templates_fast" href="#StarFormationHistories.fit_templates_fast"><code>StarFormationHistories.fit_templates_fast</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">(coeffs::Vector{::eltype(x0)}, result::Optim.MultivariateOptimizationResults) =
fit_templates_fast(models::AbstractVector{T},
                   data::AbstractMatrix{&lt;:Number};
                   x0::AbstractVector{&lt;:Number} = ones(S,length(models)),
                   kws...)
                   where {S &lt;: Number, T &lt;: AbstractMatrix{S}}</code></pre><p>Finds <em>only</em> the maximum likelihood estimate (MLE) for the coefficients <code>coeffs</code> given the provided <code>data</code> such that the best-fit composite Hess diagram model is <code>sum(models .* coeffs)</code>. This is a simplification of the main <a href="#StarFormationHistories.fit_templates"><code>fit_templates</code></a> function, which will return the MLE as well as the maximum a posteriori estimate, and further supports uncertainty quantification. For additional details on arguments to this method, see the documentation for <a href="#StarFormationHistories.fit_templates"><code>fit_templates</code></a>. </p><p>This method optimizes parameters <code>θ</code> such that <code>coeffs = θ.^2</code> – this allows for faster convergence than both the <a href="#StarFormationHistories.fit_templates_lbfgsb"><code>fit_templates_lbfgsb</code></a> method, which does not use a variable transformation, and the logarithmic transformation used in <a href="#StarFormationHistories.fit_templates"><code>fit_templates</code></a>. However, the inverse Hessian is not useful for uncertainty estimation under this transformation. As such this method only returns the MLE for <code>coeffs</code> as a vector and the result object returned by <code>Optim.optimize</code>. While this method offers fewer features than <a href="#StarFormationHistories.fit_templates"><code>fit_templates</code></a>, this method&#39;s runtime is typically half as long (or less). As such, this method is recommended for use in performance-sensitive applications like hierarchical models or hyperparameter estimation where the additional features of <a href="#StarFormationHistories.fit_templates"><code>fit_templates</code></a> are unnecessary. In these applications, the value of the objective function at the derived MLE is typically desired as well; this can be obtained the from <code>result::Optim.MultivariateOptimizationResults</code> object as <code>Optim.minimum(result)</code>. Note that this will return the <em>negative</em> loglikelihood, which is what is minimized in this application.</p><p><strong>Notes</strong></p><ol><li>By passing additional convergence keyword arguments supported by <code>Optim.Options</code> (see <a href="https://julianlsolvers.github.io/Optim.jl/stable/#user/config/">this guide</a>), it is possible to converge to the MLE in fewer than 30 iterations with fewer than 100 calls to the likelihood and gradient methods. For example, the main convergence criterion is typically the magnitude of the gradient vector, which by default is <code>g_abstol=1e-8</code>, terminating the optimization when the magnitude of the gradient is less than 1e-8. We find results are typically sufficiently accurate with <code>g_abstol=1e-3</code>, which often uses half as many objective evaluations as the default value.</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cgarling/StarFormationHistories.jl/blob/901f1c0f1a50ab9b90658688127cd8c6ecefd2e6/src/fitting/solvers.jl#L219-L233">source</a></section><section><div><pre><code class="language-julia hljs">fit_templates_fast(models::AbstractMatrix{S},
                   data::AbstractVector{&lt;:Number};
                   x0::AbstractVector{&lt;:Number} = ones(S,size(models,2)),
                   kws...)
                   where S &lt;: Number</code></pre><p>This call signature supports the flattened formats for <code>models</code> and <code>data</code>. See the notes for the flattened call signature of <a href="../internals/#StarFormationHistories.composite!"><code>StarFormationHistories.composite!</code></a> for more details.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cgarling/StarFormationHistories.jl/blob/901f1c0f1a50ab9b90658688127cd8c6ecefd2e6/src/fitting/solvers.jl#L235-L243">source</a></section></article><h2 id="Posterior-Sampling:-MCMC"><a class="docs-heading-anchor" href="#Posterior-Sampling:-MCMC">Posterior Sampling: MCMC</a><a id="Posterior-Sampling:-MCMC-1"></a><a class="docs-heading-anchor-permalink" href="#Posterior-Sampling:-MCMC" title="Permalink"></a></h2><p>For low-dimensional problems, Markov Chain Monte Carlo (MCMC) methods can be an efficient way to sample the posterior and obtain uncertainty estimates on the fitting coefficients <span>$r_j$</span>. We provide <a href="#StarFormationHistories.mcmc_sample"><code>StarFormationHistories.mcmc_sample</code></a> for this purpose. Internally this uses the multi-threaded affine-invariant MCMC sampler from <a href="https://github.com/mauro3/KissMCMC.jl">KissMCMC.jl</a> to perform the sampling, which is based on the same algorithm as Python&#39;s <a href="https://emcee.readthedocs.io/en/stable/">emcee</a> (specifically, their <code>emcee.moves.StretchMove</code>). There are other MCMC packages like <a href="https://github.com/TuringLang/AdvancedMH.jl">AdvancedMH.jl</a> that offer additional features like distributed execution. </p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StarFormationHistories.mcmc_sample" href="#StarFormationHistories.mcmc_sample"><code>StarFormationHistories.mcmc_sample</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">result::MCMCChains.Chains =
mcmc_sample(models::AbstractVector{&lt;:AbstractMatrix{T}},
            data::AbstractMatrix{S},
            x0::Union{AbstractVector{&lt;:AbstractVector{&lt;:Number}}, AbstractMatrix{&lt;:Number}},
            nsteps::Integer;
            nburnin::Integer=0,
            nthin::Integer=1,
            a_scale::Number=2.0,
            use_progress_meter::Bool=true)
mcmc_sample(models::AbstractMatrix{&lt;:Number},
            data::AbstractVector{&lt;:Number},
            args...; kws...)</code></pre><p>Samples the posterior of the coefficients <code>coeffs</code> such that the full model of the observational <code>data</code> is <code>sum(models .* coeffs)</code>. Uses the Poisson likelihood ratio as defined by equations 7–10 of Dolphin 2002. Sampling is done using the affine-invariant MCMC sampler implemented in <a href="https://github.com/mauro3/KissMCMC.jl">KissMCMC.jl</a>, which is analogous to Python&#39;s <a href="https://emcee.readthedocs.io/en/stable/">emcee.moves.StretchMove</a>. This method will automatically parallelize over threads. If you need distributed execution, you may want to look into <a href="https://github.com/TuringLang/AdvancedMH.jl">AdvancedMH.jl</a>.</p><p>The second call signature supports the flattened formats for <code>models</code> and <code>data</code>. See the notes for the flattened call signature of <a href="../internals/#StarFormationHistories.composite!"><code>StarFormationHistories.composite!</code></a> for more details.</p><p><strong>Arguments</strong></p><ul><li><code>models::AbstractVector{&lt;:AbstractMatrix{&lt;:Number}}</code> is a vector of equal-sized matrices that represent the template Hess diagrams for the simple stellar populations that compose the observed Hess diagram.</li><li><code>data::AbstractMatrix{&lt;:Number}</code> is the Hess diagram for the observed data.</li><li><code>x0::Union{AbstractVector{&lt;:AbstractVector{&lt;:Number}}, AbstractMatrix{&lt;:Number}}</code> are the initial positions for the MCMC walkers. If providing a vector of vectors, each element (i.e., <code>x0[1]</code>) is taken to be the initial position for one walker and each element must have length equal to <code>length(models)</code>. The length of <code>x0</code> is the number of MCMC walkers (<code>nwalkers</code>). You can alternatively provide a matrix of size <code>(nwalkers, length(models))</code> or <code>(length(models), nwalkers)</code>.</li><li><code>nsteps::Integer</code> is the number of steps to take with each walker.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>nburnin::Integer=0</code> is the number of steps to discard from the start of each chain.</li><li><code>nthin::Integer=1</code> is the factor by which to thin the chain; walker positions will only be saved every <code>nthin</code> steps.</li><li><code>a_scale::Number=2.0</code> is the scale parameter for the stretch move; probably shouldn&#39;t need to be changed.</li><li><code>use_progress_Meter::Bool=true</code> indicates whether or not to show a progress bar during the MCMC procedure.</li></ul><p><strong>Returns</strong></p><ul><li><code>result</code> is a <code>MCMCChains.Chains</code> instance which enables easy calculation of diagnostic and summary statistics. This type can be indexed and used like a 3-D array of samples with shape <code>(nsteps, length(models), nwalkers)</code>.</li></ul><p><strong>Notes</strong></p><ul><li>When displaying <code>result</code> to the terminal it will display summary statistics (<code>MCMCChains.summarystats</code>) and quantiles (<code>MCMCChains.quantile</code>) by calling the <code>MCMCChains.describe</code> method. This can take a second but is nice to have as an option.</li><li>The highest posterior density interval, which is the narrowest <a href="https://en.wikipedia.org/wiki/Credible_interval">credible interval</a> that includes the posterior mode, can be calculated with the <code>MCMCChains.hpd</code> method. </li><li>If you want to extract the array of samples from the <code>MCMCChains.Chains</code> object, you can index <code>result.value</code> – this will return an <code>AxisArray</code> but can be converted to a normal array with <code>Array(result.value)</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using Distributions: Poisson
coeffs = rand(10) # SFH coefficients we want to sample
models = [rand(100,100) .* 100 for i in 1:length(coeffs)] # Vector of model Hess diagrams
data = rand.(Poisson.( sum(models .* coeffs) ) ) # Poisson-sample the model `sum(models .* coeffs)`
nwalkers = 1000
nsteps = 400
x0 = rand(nwalkers, length(coeffs)) # Initial walker positions
result = mcmc_sample(models, data, x0, nsteps) # Sample
Chains MCMC chain (400×10×1000 Array{Float64, 3}) ...</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cgarling/StarFormationHistories.jl/blob/901f1c0f1a50ab9b90658688127cd8c6ecefd2e6/src/fitting/mcmc_sample.jl#L46-L96">source</a></section></article><h2 id="Posterior-Sampling:-Change-of-Variables-and-HMC"><a class="docs-heading-anchor" href="#Posterior-Sampling:-Change-of-Variables-and-HMC">Posterior Sampling: Change of Variables and HMC</a><a id="Posterior-Sampling:-Change-of-Variables-and-HMC-1"></a><a class="docs-heading-anchor-permalink" href="#Posterior-Sampling:-Change-of-Variables-and-HMC" title="Permalink"></a></h2><p><a href="https://ui.adsabs.harvard.edu/abs/2013ApJ...775...76D/abstract">Dolphin 2013</a> examined methods for obtaining uncertainties on the fitted coefficients (the <span>$r_j$</span> in Equation 1 of Dolphin 2002) and found that the Hamiltonian Monte Carlo (HMC) approach allowed for relatively efficient sampling of the posterior distribution when considering many isochrones in the modelling process. HMC requires that the variables to be fit are continuous over the real numbers and so requires a change of variables. Rather than sampling the variables <span>$r_j$</span> directly, we can sample <span>$\theta_j = \text{ln} \left( r_j \right)$</span> such that the sampled variables are continuous over the real numbers <span>$-\infty &lt; \theta_j &lt; \infty$</span> while the <span>$r_j=\text{exp} \left( \theta_j \right)$</span> coefficients are bounded from <span>$0 &lt; r_j &lt; \infty$</span>. Using a logarithmic transformation has the additional benefit that the gradient of the Poisson likelihood ratio is still continuous and easy to compute analytically.</p><p>While maximum likelihood estimates are invariant under variable transformations, sampling methods like HMC are not, as formally the posterior being sampled from is a <em>distribution</em> and therefore must be integrable over the sampling coefficients. We can write the posterior from which we wish to sample as</p><p class="math-container">\[\begin{aligned}
p(r_j | D) &amp;= \frac{p(D | r_j) \; p(r_j)}{Z} \\
p(\boldsymbol{r} | D) &amp;= \frac{1}{Z} \; \prod_j p(D | r_j) \; p(r_j) \\
-\text{ln} \; p(\boldsymbol{r} | D) &amp;= \text{ln} \, Z - \sum_j \, \text{ln} \, p(D | r_j) + \text{ln} \, p(r_j) \\
&amp;= \text{ln} \, Z - \text{ln} \, \mathscr{L} + \sum_j \text{ln} \, p(r_j)
\end{aligned}\]</p><p>where <span>$Z$</span> is the Bayesian evidence (a constant that can be neglected for sampling methods), <span>$p \left( r_j \right)$</span> is the prior on the star formation history, and <span>$\mathscr{L}$</span> is the Poisson likelihood ratio discussed above. An uninformative (and unnormalized) prior on the coefficients <span>$r_j$</span> could take the form of</p><p class="math-container">\[p(r_j) = \begin{cases}
1; &amp; r_j \geq 0\\
0; &amp; r_j &lt; 0
\end{cases}\]</p><p>such that, if the coefficients <span>$r_j$</span> are guaranteed to be positive, the final term becomes zero (since <span>$\text{ln}(1)=0$</span>) and</p><p class="math-container">\[-\text{ln} \; p(\boldsymbol{r} | D) = \text{ln} \, Z - \text{ln} \, \mathscr{L}\]</p><p>When sampling with methods like HMC, constants like <span>$\text{ln} \, Z$</span> can be neglected and <span>$-\text{ln} \; p(\boldsymbol{r} | D) \propto - \text{ln} \, \mathscr{L}$</span> such that the posterior is approximated by the likelihood surface.</p><p>Let us consider now what happens when we wish to do a variable transformation from <span>$r_j$</span> to <span>$\theta_j = \text{ln} (r_j)$</span>. From above we can write the posterior as</p><p class="math-container">\[p(r_j | D) = \frac{p(D | r_j) \; p(r_j)}{Z} \\\]</p><p>Under the change of variables formula we can write</p><p class="math-container">\[\begin{aligned}
p(\theta_j | D) &amp;= p(r_j | D) \left| \frac{d r_j}{d \theta_j} \right| \\
&amp;= p(r_j | D) \left| \frac{d \theta_j}{d r_j} \right|^{-1}
\end{aligned}\]</p><p>where <span>$\left| \frac{d \theta_j}{d r_j} \right|^{-1}$</span> is often called the Jacobian correction. We choose <span>$\theta_j$</span> such that</p><p class="math-container">\[\begin{aligned}
\theta_j &amp;= \text{ln} ( r_j ) \\
\left| \frac{d \theta_j}{d r_j} \right| &amp;= \frac{1}{r_j} \\
r_j &amp;= \text{exp} (\theta_j) \\
\end{aligned}\]</p><p>which leads to a posterior of</p><p class="math-container">\[p(\theta_j | D) = \text{exp} (\theta_j) \times p(\text{exp} (\theta_j) | D) = r_j \times p(r_j | D) \\\]</p><p>We can then write the product over the <span>$\theta_j$</span> as</p><p class="math-container">\[\begin{aligned}
p(\boldsymbol{\theta} | D) &amp;= \frac{1}{Z} \; \prod_j r_j \; p(D | r_j) \; p(r_j) \\
-\text{ln} \, p(\boldsymbol{\theta} | D) &amp;= \text{ln} \, Z - \sum_j \text{ln} \, (r_j) + \text{ln} \, p(D | r_j) + \text{ln} \, p(r_j) \\
&amp;= \text{ln} \, Z - \sum_j \text{ln} \, p(D | r_j) + \text{ln} \, p(r_j) - \sum_j \theta_j \\
&amp;= -\text{ln} \, p(\boldsymbol{r} | D) - \sum_j \theta_j \\
&amp;= -\text{ln} \, p(\boldsymbol{r} | D) - \sum_j \text{ln} \, (r_j)
\end{aligned}\]</p><p>The choice of a logarithmic transformation means that the negative logarithm of the posterior (which is what HMC uses for its objective function) has this very simple form which allows for simple analytic gradients as well. Once samples of <span>$\theta$</span> have been obtained from this distribution via HMC or any other sampling method, they can be directly transformed back to the standard coefficients <span>$r_j = \text{exp}(\theta_j)$</span>.</p><p>The method <a href="#StarFormationHistories.hmc_sample"><code>hmc_sample</code></a> implements this approach for sampling the <span>$\theta_j$</span> coefficients; these samples can then be used to estimate random uncertainties on the derived star formation history.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StarFormationHistories.hmc_sample" href="#StarFormationHistories.hmc_sample"><code>StarFormationHistories.hmc_sample</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">hmc_sample(models::AbstractVector{T},
           data::AbstractMatrix{&lt;:Number},
           nsteps::Integer [, nchains::Integer];
           rng::Random.AbstractRNG=Random.default_rng(),
           kws...)
           where {S &lt;: Number, T &lt;: AbstractMatrix{S}}
hmc_sample(models::AbstractMatrix{S},
           data::AbstractVector{&lt;:Number},
           nsteps::Integer;
           rng::AbstractRNG=default_rng(),
           kws...)
           where S &lt;: Number</code></pre><p>Function to sample the posterior of the coefficients <code>coeffs</code> such that the full model of the observational <code>data</code> is <code>sum(models .* coeffs)</code>. Uses the Poisson likelihood ratio as defined by equations 7–10 of Dolphin 2002 along with a logarithmic transformation of the <code>coeffs</code> so that the fitting variables are continuous and differentiable over all reals. Sampling is done using the No-U-Turn sampler as implemented in <a href="https://github.com/tpapp/DynamicHMC.jl">DynamicHMC.jl</a>, which is a form of dynamic Hamiltonian Monte Carlo.</p><p>The second call signature supports the flattened formats for <code>models</code> and <code>data</code>. See the notes for the flattened call signature of <a href="../internals/#StarFormationHistories.composite!"><code>StarFormationHistories.composite!</code></a> for more details.</p><p><strong>Arguments</strong></p><ul><li><code>models::AbstractVector{&lt;:AbstractMatrix{&lt;:Number}}</code> is a vector of equal-sized matrices that represent the template Hess diagrams for the simple stellar populations that compose the observed Hess diagram.</li><li><code>data::AbstractMatrix{&lt;:Number}</code> is the Hess diagram for the observed data.</li><li><code>nsteps::Integer</code> is the number of samples to draw per chain.</li></ul><p><strong>Optional Arguments</strong></p><ul><li><code>nchains::Integer</code>: If this argument is not provided, this method will return a single chain. If this argument is provided, it will sample <code>nchains</code> chains using all available Julia threads and will return a vector of the individual chains.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>rng::Random.AbstractRNG</code> is the random number generator that will be passed to DynamicHMC.jl. If <code>nchains</code> is provided this method will attempt to sample in parallel, requiring a thread-safe <code>rng</code> such as that provided by <code>Random.default_rng()</code>. </li></ul><p>All other keyword arguments <code>kws...</code> will be passed to <code>DynamicHMC.mcmc_with_warmup</code> or <code>DynamicHMC.mcmc_keep_warmup</code> depending on whether <code>nchains</code> is provided.</p><p><strong>Returns</strong></p><ul><li>If <code>nchains</code> is not provided, returns a <code>NamedTuple</code> as summarized in DynamicHMC.jl&#39;s documentation. In short, the matrix of samples can be extracted and transformed as <code>exp.( result.posterior_matrix )</code>. Statistics about the chain can be obtained with <code>DynamicHMC.Diagnostics.summarize_tree_statistics(result.tree_statistics)</code>; you want to see a fairly high acceptance rate (&gt;0.5) and the majority of samples having termination criteria being &quot;turning.&quot; See DynamicHMC.jl&#39;s documentation for more information.</li><li>If <code>nchains</code> <em>is</em> provided, returns a vector of length <code>nchains</code> of the same <code>NamedTuple</code>s described above. The samples from each chain in the returned vector can be stacked to a single <code>(nsamples, nchains, length(models))</code> matrix with <code>DynamicHMC.stack_posterior_matrices(result)</code>. </li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">import DynamicHMC
import StatFormationHistories: hmc_sample
import Statistics: mean
# Run sampler using progress meter to monitor progress
# assuming you have constructed some templates `models` and your observational Hess diagram `data`
result = hmc_sample( models, data, 1000; reporter=DynamicHMC.ProgressMeterReport())
# The chain values are stored in result.posterior matrix; extract them with `result.posterior_matrix`
# An exponential transformation is needed since the optimization internally uses a logarithmic 
# transformation and samples log(θ) rather than θ directly. 
mc_matrix = exp.( result.posterior_matrix )
# We can look at some statistics from the chain; want to see high acceptance rate (&gt;0.5) and large % of
# &quot;turning&quot; for termination criteria. 
DynamicHMC.Diagnostics.summarize_tree_statistics(result.tree_statistics)
    Hamiltonian Monte Carlo sample of length 1000
      acceptance rate mean: 0.92, 5/25/50/75/95%: 0.65 0.88 0.97 1.0 1.0
      termination: divergence =&gt; 0%, max_depth =&gt; 0%, turning =&gt; 100%
      depth: 0 =&gt; 0%, 1 =&gt; 64%, 2 =&gt; 36%
# mc_matrix has size `(length(models), nsteps)` so each column is an independent
# sample of the SFH as defined by the coefficients and the rows contain the samples
# for each parameter. 
mstar_tot = sum.(eachcol(mc_matrix)) # Total stellar mass of the modelled system per sample
mc_means = mean.(eachrow(mc_matrix)) # Mean of each coefficient evaluated across all samples
# Example with multiple chains sampled in parallel via multi-threading
import Threads
t_result = hmc_sample( models, data, 1000, Threads.nthreads(); reporter=DynamicHMC.ProgressMeterReport())
# Combine the multiple chains into a single matrix and transform
# Can then use the same way as `mc_matrix` above
mc_matrix = exp.( DynamicHMC.pool_posterior_matrices(t_result) )</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cgarling/StarFormationHistories.jl/blob/901f1c0f1a50ab9b90658688127cd8c6ecefd2e6/src/fitting/hmc_sample.jl#L39-L104">source</a></section></article><p>See the <a href="https://github.com/tpapp/DynamicHMC.jl">DynamicHMC.jl</a> documentation for more information on how to use the chains that are output by this method.</p><p>Inspection of the samples generated by <code>hmc_sample</code> shows that the posterior defined by the above model is typically smooth, well-behaved, and unimodal. In particular, we find that the sampled <span>$r_j$</span> for coefficients that are non-zero in the MLE are approximately Gaussian distributed while the logarithms of the sampled <span>$r_j$</span> are roughly Gaussian distributed for coefficients that are zero in the MLE; i.e.</p><p class="math-container">\[\begin{cases}
X_j \sim \mathcal{N}; &amp; \hat r_j &gt; 0 \\
\text{ln} \left( X_j \right) \sim \mathcal{N}; &amp; \hat r_j = 0 \\
\end{cases}\]</p><p>where <span>$X_j$</span> are the samples of <span>$r_j$</span> obtained from the posterior and <span>$\hat r_j$</span> is the maximum likelihood estimate of <span>$r_j$</span>. </p><p>This indicates we may be able to approximate the posterior in the region surrounding the maximum a posteriori (MAP) value by the inverse of the Hessian matrix (see, e.g., <a href="https://doi.org/10.1016/0893-9659(91)90129-J">Dovi et al. 1991</a>), allowing us to estimate parameter uncertainties very cheaply. The inverse of the Hessian matrix is exactly equal to the variance-covariance matrix of the parameters for a Gaussian probability distribution; for other probability distributions, the inverse of the Hessian approximates the variance-covariance matrix of the parameters when the second-order expansion defined by the Hessian at the maximum is a reasonable approximation to the real objective function being optimized. A particularly simple form arises when the logarithm of the objective is quadratic in the fitting parameters, as in the Gaussian case, because the second derivatives of the objective are constant and do not depend on the fitting parameters or the MAP estimate.</p><h2 id="Maximum-a-Posteriori-Optimization"><a class="docs-heading-anchor" href="#Maximum-a-Posteriori-Optimization">Maximum a Posteriori Optimization</a><a id="Maximum-a-Posteriori-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Maximum-a-Posteriori-Optimization" title="Permalink"></a></h2><p>Direct computation of the Hessian and its inverse is expensive, so we&#39;d like another way to obtain it. The first-order, quasi-Newton BFGS optimization algorithm provides such a method as it iteratively builds a dense approximation to the inverse Hessian using the change in the gradient of the objective, which we can compute analytically. It is, however, much less memory efficient than the LBFGS algorithm we use in <a href="#StarFormationHistories.fit_templates_lbfgsb"><code>StarFormationHistories.fit_templates_lbfgsb</code></a>. For moderate isochrone grids up to a few hundred model templates, this is not a problem. Beyond this it may be better to use <a href="#StarFormationHistories.fit_templates_lbfgsb"><code>StarFormationHistories.fit_templates_lbfgsb</code></a> to obtain the MLE and <a href="#StarFormationHistories.hmc_sample"><code>hmc_sample</code></a> to obtain posterior samples.</p><p>We implement this optimization scheme in <a href="#StarFormationHistories.fit_templates"><code>fit_templates</code></a>, <strong>which is our recommended method for unconstrained SFH fitting</strong> (i.e., direct fitting of the <span>$r_j$</span> coefficients). See the next section for notes on more complicated, hierarchical models that can incorporate features like metallicity distribution functions.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StarFormationHistories.fit_templates" href="#StarFormationHistories.fit_templates"><code>StarFormationHistories.fit_templates</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">result = fit_templates(models::AbstractVector{T},
                       data::AbstractMatrix{&lt;:Number};
                       x0::AbstractVector{&lt;:Number} = ones(S,length(models)),
                       kws...) where {S &lt;: Number, T &lt;: AbstractMatrix{S}}</code></pre><p>Finds both maximum likelihood estimate (MLE) and maximum a posteriori estimate (MAP) for the coefficients <code>coeffs</code> such that the composite Hess diagram model is <code>sum(models .* coeffs)</code> using the provided templates <code>models</code> and the observed Hess diagram <code>data</code>. Utilizes the Poisson likelihood ratio (equations 7–10 in <a href="https://ui.adsabs.harvard.edu/abs/2002MNRAS.332...91D">Dolphin 2002</a>) for the likelihood of the data given the model. See the examples in the documentation for comparisons of the results of this method and <a href="#StarFormationHistories.hmc_sample"><code>hmc_sample</code></a> which samples the posterior via Hamiltonian Monte Carlo. </p><p><strong>Arguments</strong></p><ul><li><code>models::AbstractVector{AbstractMatrix{&lt;:Number}}</code>: the list of template Hess diagrams for the simple stellar populations (SSPs) being considered; all must have the same size.</li><li><code>data::AbstractMatrix{&lt;:Number}</code>: the observed Hess diagram; must match the size of the templates contained in <code>models</code>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>x0</code>: The vector of initial guesses for the stellar mass coefficients. You should basically always be calculating and passing this keyword argument; we provide <a href="#StarFormationHistories.construct_x0"><code>StarFormationHistories.construct_x0</code></a> to prepare <code>x0</code> assuming constant star formation rate, which is typically a good initial guess.</li></ul><p>Other <code>kws...</code> are passed to <code>Optim.options</code> to set things like convergence criteria for the optimization. </p><p><strong>Returns</strong></p><p><code>result</code> is a <code>NamedTuple</code> containing two <a href="#StarFormationHistories.LogTransformFTResult"><code>StarFormationHistories.LogTransformFTResult</code></a>. The two components of <code>result</code> are <code>result.map</code> or <code>result[1]</code>, which contains the results of the MAP optimization, and <code>result.mle</code> or <code>result[2]</code>, which contains the results of the MLE optimization. The documentation for <a href="#StarFormationHistories.LogTransformFTResult"><code>StarFormationHistories.LogTransformFTResult</code></a> contains more information about these types, but briefly they contain the following fields, accessible as, e.g., <code>result.map.μ</code>, <code>result.map.σ</code>, etc.:</p><ul><li><code>μ::Vector{&lt;:Number}</code> are the optimized <code>coeffs</code> at the maximum.</li><li><code>σ::Vector{&lt;:Number}</code> are the standard errors on the coeffs <code>μ</code> calculated from an estimate of the inverse Hessian matrix evaluated at <code>μ</code>. The inverse of the Hessian matrix at the maximum of the likelihood (or posterior) is a estimator for the variance-covariance matrix of the parameters, but is only accurate when the second-order expansion given by the Hessian at the maximum is a good approximation to the function being optimized (i.e., when the optimized function is approximately quadratic around the maximum; see <a href="https://doi.org/10.1016/0893-9659(91)90129-J">Dovi et al. 1991</a> for more information). We find this is often the case for the MAP estimate, but the errors found for coefficients that are ≈0 in the MLE are typically unrealistically small. For coefficients significantly greater than 0, the <code>σ</code> values from the MAP and MLE are typically consistent to 5–10%.</li><li><code>invH::Matrix{&lt;:Number}</code> is the estimate of the inverse Hessian matrix at <code>μ</code> that was used to derive <code>σ</code>. The optimization is done under a logarithmic transform, such that <code>θ[j] = log(coeffs[j])</code> are the actual parameters optimized, so the entries in the Hessian are actually</li></ul><p class="math-container">\[H^{(j,k)} ( \boldsymbol{\hat \theta} ) = \left. \frac{\partial^2 \, J(\boldsymbol{\theta})}{\partial \theta_j \, \partial \theta_k} \right\vert_{\boldsymbol{\theta}=\boldsymbol{\hat \theta}}\]</p><ul><li><code>result</code> is the full object returned by the optimization from <code>Optim.jl</code>; this is of type <code>Optim.MultivariateOptimizationResults</code>. Remember that the optimization is done with parameters <code>θ[j] = log(coeffs[j])</code> when dealing with this raw output. This means that, for example, we calculate <code>result.map.μ</code> as <code>exp.(Optim.minimizer(result.map.result))</code>.</li></ul><p>The special property of the <a href="#StarFormationHistories.LogTransformFTResult"><code>StarFormationHistories.LogTransformFTResult</code></a> type is that you can draw a set of <code>N::Integer</code> random parameter samples from the result using the inverse Hessian approximation discussed above by doing <code>rand(result.map, N)</code>. This type implements the random sampling API of <code>Distributions.jl</code> so the other standard sampling methods should work as well. In our tests these samples compare very favorably against those from <a href="#StarFormationHistories.hmc_sample"><code>hmc_sample</code></a>, which samples the posterior via Hamiltonian Monte Carlo and is therefore more robust but much more expensive. We compare these methods in the examples.</p><p><strong>Notes</strong></p><ul><li>This method uses the <code>BFGS</code> method from <code>Optim.jl</code> internally because it builds and tracks the inverse Hessian matrix approximation which can be used to estimate parameter uncertainties. BFGS is much more memory-intensive than LBFGS (as used for <a href="#StarFormationHistories.fit_templates_lbfgsb"><code>StarFormationHistories.fit_templates_lbfgsb</code></a>) for large numbers of parameters (equivalently, many <code>models</code>), so you should consider LBFGS to solve for the MLE along with <a href="#StarFormationHistories.hmc_sample"><code>hmc_sample</code></a> to sample the posterior if you are using a large grid of models (greater than a few hundred).</li><li>The BFGS implementation we use from Optim.jl uses BLAS operations during its iteration. The OpenBLAS that Julia ships with will often default to running on multiple threads even if Julia itself is started with only a single thread. You can check the current number of BLAS threads with <code>import LinearAlgebra: BLAS; BLAS.get_num_threads()</code>. For the problem sizes typical of this function we actually see performance regression with larger numbers of BLAS threads. For this reason you may wish to use BLAS in single-threaded mode; you can set this as <code>import LinearAlgebra: BLAS; BLAS.set_num_threads(1)</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cgarling/StarFormationHistories.jl/blob/901f1c0f1a50ab9b90658688127cd8c6ecefd2e6/src/fitting/solvers.jl#L129-L160">source</a></section><section><div><pre><code class="language-julia hljs">fit_templates(models::AbstractMatrix{S},
              data::AbstractVector{&lt;:Number};
              x0::AbstractVector{&lt;:Number} = ones(S,length(models)),
              kws...) where S &lt;: Number</code></pre><p>This call signature supports the flattened formats for <code>models</code> and <code>data</code>. See the notes for the flattened call signature of <a href="../internals/#StarFormationHistories.composite!"><code>StarFormationHistories.composite!</code></a> for more details.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cgarling/StarFormationHistories.jl/blob/901f1c0f1a50ab9b90658688127cd8c6ecefd2e6/src/fitting/solvers.jl#L162-L169">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StarFormationHistories.LogTransformFTResult" href="#StarFormationHistories.LogTransformFTResult"><code>StarFormationHistories.LogTransformFTResult</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LogTransformFTResult(μ::AbstractVector{&lt;:Number},
                     σ::AbstractVector{&lt;:Number},
                     invH::AbstractMatrix{&lt;:Number},
                     result)</code></pre><p>Type for containing the maximum likelihood estimate (MLE) and maximum a posteriori (MAP) results from <a href="#StarFormationHistories.fit_templates"><code>fit_templates</code></a>. The fitted coefficients are available in the <code>μ</code> field. Estimates of the standard errors are available in the <code>σ</code> field. These have both been transformed from the native logarithmic fitting space into natural units (i.e., stellar mass or star formation rate).</p><p><code>invH</code> contains the estimated inverse Hessian of the likelihood / posterior at the maximum point in the logarithmic fitting units. <code>result</code> is the full result object returned by the optimization routine.</p><p>This type is implemented as a subtype of <code>Distributions.Sampleable{Multivariate, Continuous}</code> to enable sampling from an estimate of the likelihood / posterior distribution. We approximate the distribution as a multivariate Gaussian in the native (logarithmically transformed) fitting variables with covariance matrix <code>invH</code> and means <code>log.(μ)</code>. We find this approximation is good for the MAP result but less robust for the MLE. You can obtain <code>N::Integer</code> samples from the distribution by <code>rand(R, N)</code> where <code>R</code> is an instance of this type; this will return a size <code>length(μ) x N</code> matrix, or fail if <code>invH</code> is not positive definite.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; result = fit_templates(models, data);

julia&gt; typeof(result.map)
StarFormationHistories.LogTransformFTResult{...}

julia&gt; size(rand(result.map, 3)) == (length(models),3)
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cgarling/StarFormationHistories.jl/blob/901f1c0f1a50ab9b90658688127cd8c6ecefd2e6/src/fitting/solvers.jl#L90-L112">source</a></section></article><p>Once you have obtained stellar mass coefficients from the above methods, you can convert them into star formation rates and compute per-age mean metallicities with <a href="#StarFormationHistories.calculate_cum_sfr"><code>StarFormationHistories.calculate_cum_sfr</code></a>.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StarFormationHistories.calculate_cum_sfr" href="#StarFormationHistories.calculate_cum_sfr"><code>StarFormationHistories.calculate_cum_sfr</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">(unique_logAge, cum_sfh, sfr, mean_MH) =
    calculate_cum_sfr(coeffs::AbstractVector,
                      logAge::AbstractVector,
                      MH::AbstractVector,
                      T_max::Number;
                      normalize_value=1,
                      sorted::Bool=false)</code></pre><p>Calculates cumulative star formation history, star formation rates, and mean metallicity evolution as functions of <code>logAge = log10(age [yr])</code>.</p><p><strong>Arguments</strong></p><ul><li><code>coeffs::AbstractVector</code> is a vector of stellar mass coefficients such as those returned by <a href="#StarFormationHistories.fit_templates"><code>fit_templates</code></a>, for example. Actual stellar mass in stellar population <code>j</code> is <code>coeffs[j] * normalize_value</code>.</li><li><code>logAge::AbstractVector</code> is a vector giving the <code>log10(age [yr])</code> of the stellar populations corresponding to the provided <code>coeffs</code>. For the purposes of calculating star formation rates, these are assumed to be left-bin edges.</li><li><code>MH::AbstractVector</code> is a vector giving the metallicities of the stellar populations corresponding to the provided <code>coeffs</code>.</li><li><code>T_max::Number</code> is the rightmost final bin edge for calculating star formation rates in units of Gyr. For example, you might have <code>logAge=[6.6, 6.7, 6.8]</code> in which case a final logAge of 6.9 would give equal bin widths. In this case you would set <code>T_max = exp10(6.9) / 1e9 ≈ 0.0079</code> so that the width of the final bin for the star formation rate calculation has the same <code>log10(Age [yr])</code> step as the other bins.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>normalize_value</code> is a multiplicative prefactor to apply to all the <code>coeffs</code>; same as the keyword in <a href="../fitting_intro/#StarFormationHistories.partial_cmd_smooth"><code>partial_cmd_smooth</code></a>.</li><li><code>sorted::Bool</code> is either <code>true</code> or <code>false</code> and signifies whether to assume <code>logAge</code> is sorted.</li></ul><p><strong>Returns</strong></p><ul><li><code>unique_logAge::Vector</code> is essentially <code>unique(sort(logAge))</code> and provides the x-values you would plot the other returned vectors against.</li><li><code>cum_sfh::Vector</code> is the normalized cumulative SFH implied by the provided <code>coeffs</code>. This is ~1 at the most recent time in <code>logAge</code> and decreases as <code>logAge</code> increases.</li><li><code>sfr::Vector</code> gives the star formation rate across each bin in <code>unique_logAge</code>. If <code>coeffs .* normalize_value</code> are in units of solar masses, then <code>sfr</code> is in units of solar masses per year.</li><li><code>mean_MH::Vector</code> gives the stellar-mass-weighted mean metallicity of the stellar population as a function of <code>unique_logAge</code>. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cgarling/StarFormationHistories.jl/blob/901f1c0f1a50ab9b90658688127cd8c6ecefd2e6/src/fitting/utilities.jl#L49-L75">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../fitting_intro/">« Background and Template Construction</a><a class="docs-footer-nextpage" href="../hierarchical/overview/">Overview »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.11.4 on <span class="colophon-date" title="Sunday 25 May 2025 02:12">Sunday 25 May 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
